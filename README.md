# Residual-Squeeze-VGG16
Compressed Residual-VGG16 CNN Model for Big Data Places Image Recognition

Deep learning has given way to a new era of machine learning,
apart from computer vision. Convolutional neural networks have
been implemented in image classification, segmentation and object
detection. Despite recent advancements, we are still in the very
early stages and have yet to settle on best practices for network
architecture in terms of deep design, small in size and a short
training time. In this paper, we address the issue of speed and size
by proposing a compressed convolutional neural network model
namely Residual Squeeze VGG16. Proposed model compresses the
earlier very successful VGG16 network and further improves on
following aspects: (1) small model size, (2) faster speed, (3) uses
residual learning for faster convergence, better generalization, and
solves the issue of degradation, (4) matches the recognition
accuracy of the non-compressed model on the very large-scale
grand challenge MIT Places 365-Standard scene dataset.
In comparison to VGG16 the proposed model is 88.4%
smaller in size and 23.86% faster in the training time. This
supports our claim that the proposed model inherits the best aspects
of VGG16 and further improves upon it. In comparison to
SqueezeNet our proposed framework can be more easily adapted
and fully integrated with the residual learning for compressing
various other contemporary deep learning convolutional neural
network models Broader impact of our work could improve the
performance in specialized tasks such as video-based surveillance,
self-driving cars, and mobile GPU applications.

Please cite the original paper: https://arxiv.org/abs/1705.03004
